"""
Enhanced ROSE Trainer with Adaptive Augmentation
è®­ç»ƒè¿‡ç¨‹ä¸­å®ç°æ•°æ®å¢å¼ºè¾“å‡ºã€ç­–ç•¥ä¿å­˜ã€è‡ªåŠ¨éªŒè¯è¯„ä¼°å’Œç­–ç•¥ä¼˜åŒ–
"""

import os
import json
import yaml
import numpy as np
import torch
import pickle
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import matplotlib.pyplot as plt
import cv2
from mmengine.config import Config
from mmengine.runner import Runner
from mmengine.hooks import Hook
from mmengine.registry import HOOKS

@HOOKS.register_module()
class EnhancedROSETrainingHook(Hook):
    """å¢å¼ºçš„ROSEè®­ç»ƒé’©å­ï¼Œå®ç°å®Œæ•´çš„è‡ªé€‚åº”å¢å¼ºè®­ç»ƒæµç¨‹"""
    
    def __init__(self,
                 work_dir: str,
                 save_augmented_samples: bool = True,
                 samples_per_epoch: int = 50,
                 visualization_enabled: bool = True,
                 auto_validation: bool = True,
                 strategy_adaptation: bool = True,
                 performance_analysis: bool = True,
                 priority: int = 'NORMAL',
                 **kwargs):
        super().__init__()
        
        self.work_dir = Path(work_dir)
        self.save_augmented_samples = save_augmented_samples
        self.samples_per_epoch = samples_per_epoch
        self.visualization_enabled = visualization_enabled
        self.auto_validation = auto_validation
        self.strategy_adaptation = strategy_adaptation
        self.performance_analysis = performance_analysis
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self.setup_directories()
        
        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.training_history = {
            'epochs': [],
            'losses': [],
            'val_maps': [],
            'strategies': [],
            'performance_analysis': []
        }
        
        # å½“å‰å¢å¼ºç­–ç•¥
        self.current_strategy = self.get_initial_strategy()
        
        # ä¿å­˜çš„å¢å¼ºæ ·æœ¬è®¡æ•°å™¨
        self.saved_samples_count = 0
        
        print(f"âœ… å¢å¼ºROSEè®­ç»ƒé’©å­åˆå§‹åŒ–å®Œæˆ")
        print(f"   å·¥ä½œç›®å½•: {self.work_dir}")
        print(f"   ä¿å­˜å¢å¼ºæ ·æœ¬: {self.save_augmented_samples}")
        print(f"   è‡ªåŠ¨éªŒè¯: {self.auto_validation}")
        print(f"   ç­–ç•¥è‡ªé€‚åº”: {self.strategy_adaptation}")
    
    def setup_directories(self):
        """åˆ›å»ºå®Œæ•´çš„è¾“å‡ºç›®å½•ç»“æ„"""
        self.aug_output_dir = self.work_dir / 'augmented_outputs'
        self.strategy_dir = self.work_dir / 'augmentation_strategies'
        self.validation_dir = self.work_dir / 'validation_results'
        self.visualization_dir = self.work_dir / 'visualizations'
        self.analysis_dir = self.work_dir / 'performance_analysis'
        
        for dir_path in [self.aug_output_dir, self.strategy_dir, 
                        self.validation_dir, self.visualization_dir, 
                        self.analysis_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # ä¸ºæ¯ä¸ªå¤©æ°”æ¡ä»¶åˆ›å»ºå­ç›®å½•
        weather_types = ['clear', 'rain', 'snow', 'fog']
        for weather in weather_types:
            (self.aug_output_dir / weather / 'images').mkdir(parents=True, exist_ok=True)
            (self.aug_output_dir / weather / 'pointclouds').mkdir(parents=True, exist_ok=True)
    
    def get_initial_strategy(self) -> Dict:
        """è·å–åˆå§‹å¢å¼ºç­–ç•¥"""
        return {
            'epoch': 0,
            'weather_probabilities': {
                'clear': 0.4,
                'rain': 0.2,
                'snow': 0.2,  
                'fog': 0.2
            },
            'intensity_levels': {
                'rain': 0.3,
                'snow': 0.4,
                'fog': 0.5
            },
            'adaptation_params': {
                'performance_threshold': 0.65,
                'improvement_rate': 0.02,
                'min_intensity': 0.1,
                'max_intensity': 0.8
            }
        }
    
    def before_run(self, runner) -> None:
        """è®­ç»ƒå¼€å§‹å‰çš„åˆå§‹åŒ–"""
        print("ğŸš€ å¼€å§‹å¢å¼ºROSEè®­ç»ƒæµç¨‹...")
        
        # ä¿å­˜åˆå§‹ç­–ç•¥
        self.save_strategy(0, self.current_strategy)
        
        # åˆå§‹åŒ–è®­ç»ƒå†å²è®°å½•
        history_file = self.work_dir / 'training_history.json'
        with open(history_file, 'w') as f:
            json.dump(self.training_history, f, indent=2)
    
    def before_train_epoch(self, runner) -> None:
        """æ¯ä¸ªè®­ç»ƒè½®æ¬¡å¼€å§‹å‰"""
        current_epoch = runner.epoch
        print(f"\\nğŸ“Š å¼€å§‹ç¬¬ {current_epoch + 1} è½®è®­ç»ƒ")
        print(f"å½“å‰å¢å¼ºç­–ç•¥: {self.current_strategy['weather_probabilities']}")
        
        # é‡ç½®æ ·æœ¬è®¡æ•°å™¨
        self.saved_samples_count = 0
        
        # æ›´æ–°ç­–ç•¥ä¸­çš„è½®æ¬¡ä¿¡æ¯
        self.current_strategy['epoch'] = current_epoch
    
    def after_train_iter(self, runner, batch_idx: int, data_batch: Any, outputs: Dict) -> None:
        """è®­ç»ƒè¿­ä»£åå¤„ç† - ä¿å­˜å¢å¼ºæ ·æœ¬"""
        if not self.save_augmented_samples:
            return
            
        # é™åˆ¶æ¯è½®ä¿å­˜çš„æ ·æœ¬æ•°é‡
        if self.saved_samples_count >= self.samples_per_epoch:
            return
        
        current_epoch = runner.epoch
        
        # æ¯20ä¸ªbatchä¿å­˜ä¸€æ¬¡æ ·æœ¬
        if batch_idx % 20 == 0:
            self.save_augmented_sample(data_batch, current_epoch, batch_idx)
            self.saved_samples_count += 1
    
    def save_augmented_sample(self, data_batch: Any, epoch: int, batch_idx: int):
        """ä¿å­˜å¢å¼ºåçš„æ ·æœ¬æ•°æ®"""
        try:
            # éšæœºé€‰æ‹©ä¸€ä¸ªå¤©æ°”ç±»å‹è¿›è¡Œå¢å¼º
            weather_types = list(self.current_strategy['weather_probabilities'].keys())
            weather_probs = list(self.current_strategy['weather_probabilities'].values())
            selected_weather = np.random.choice(weather_types, p=weather_probs)
            
            if selected_weather == 'clear':
                return  # æ¸…æ™°å¤©æ°”ä¸éœ€è¦ä¿å­˜å¢å¼ºæ ·æœ¬
            
            # è·å–æ‰¹æ¬¡æ•°æ®
            if hasattr(data_batch, 'data_samples'):
                sample = data_batch.data_samples[0] if len(data_batch.data_samples) > 0 else None
            elif isinstance(data_batch, dict):
                sample = data_batch
            else:
                return
            
            if sample is None:
                return
            
            # ä¿å­˜å›¾åƒæ•°æ®
            if 'img' in sample:
                self.save_augmented_image(sample['img'], selected_weather, epoch, batch_idx)
            
            # ä¿å­˜ç‚¹äº‘æ•°æ®  
            if 'points' in sample:
                self.save_augmented_pointcloud(sample['points'], selected_weather, epoch, batch_idx)
            
            print(f"âœ… ä¿å­˜å¢å¼ºæ ·æœ¬: Epoch{epoch}_Batch{batch_idx}_{selected_weather}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¢å¼ºæ ·æœ¬å¤±è´¥: {e}")
    
    def save_augmented_image(self, img_tensor: torch.Tensor, weather: str, epoch: int, batch_idx: int):
        """ä¿å­˜å¢å¼ºåçš„å›¾åƒ"""
        try:
            # è½¬æ¢tensorä¸ºnumpyæ•°ç»„
            if isinstance(img_tensor, torch.Tensor):
                img_np = img_tensor.detach().cpu().numpy()
            else:
                img_np = img_tensor
            
            # å¤„ç†å›¾åƒç»´åº¦ (C, H, W) -> (H, W, C)
            if len(img_np.shape) == 3 and img_np.shape[0] in [1, 3]:
                img_np = np.transpose(img_np, (1, 2, 0))
            
            # å½’ä¸€åŒ–åˆ°0-255
            if img_np.max() <= 1.0:
                img_np = (img_np * 255).astype(np.uint8)
            
            # åº”ç”¨å¤©æ°”å¢å¼ºæ•ˆæœ
            augmented_img = self.apply_weather_augmentation(img_np, weather)
            
            # ä¿å­˜å›¾åƒ
            output_path = self.aug_output_dir / weather / 'images' / f'epoch_{epoch}_batch_{batch_idx}.jpg'
            cv2.imwrite(str(output_path), augmented_img)
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¢å¼ºå›¾åƒå¤±è´¥: {e}")
    
    def save_augmented_pointcloud(self, points_tensor: torch.Tensor, weather: str, epoch: int, batch_idx: int):
        """ä¿å­˜å¢å¼ºåçš„ç‚¹äº‘"""
        try:
            # è½¬æ¢tensorä¸ºnumpyæ•°ç»„
            if isinstance(points_tensor, torch.Tensor):
                points_np = points_tensor.detach().cpu().numpy()
            else:
                points_np = points_tensor
            
            # åº”ç”¨å¤©æ°”å¢å¼ºæ•ˆæœ (ç®€åŒ–ç‰ˆæœ¬)
            augmented_points = self.apply_pointcloud_weather_augmentation(points_np, weather)
            
            # ä¿å­˜ç‚¹äº‘æ•°æ®
            output_path = self.aug_output_dir / weather / 'pointclouds' / f'epoch_{epoch}_batch_{batch_idx}.npy'
            np.save(str(output_path), augmented_points)
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¢å¼ºç‚¹äº‘å¤±è´¥: {e}")
    
    def apply_weather_augmentation(self, img: np.ndarray, weather: str) -> np.ndarray:
        """åº”ç”¨å¤©æ°”å¢å¼ºæ•ˆæœåˆ°å›¾åƒ"""
        augmented = img.copy()
        
        if weather == 'rain':
            # é›¨å¤©æ•ˆæœï¼šé™ä½äº®åº¦ï¼Œå¢åŠ å™ªå£°
            augmented = cv2.convertScaleAbs(augmented, alpha=0.8, beta=-10)
            noise = np.random.normal(0, 5, augmented.shape).astype(np.uint8)
            augmented = cv2.add(augmented, noise)
            
        elif weather == 'snow':
            # é›ªå¤©æ•ˆæœï¼šå¢åŠ äº®åº¦ï¼Œæ·»åŠ é›ªèŠ±å™ªå£°
            augmented = cv2.convertScaleAbs(augmented, alpha=1.1, beta=20)
            # æ·»åŠ é›ªèŠ±æ•ˆæœ
            snow_mask = np.random.random(augmented.shape[:2]) < 0.005
            augmented[snow_mask] = 255
            
        elif weather == 'fog':
            # é›¾å¤©æ•ˆæœï¼šé™ä½å¯¹æ¯”åº¦ï¼Œå¢åŠ äº®åº¦
            augmented = cv2.convertScaleAbs(augmented, alpha=0.7, beta=30)
            # æ·»åŠ é«˜æ–¯æ¨¡ç³Š
            augmented = cv2.GaussianBlur(augmented, (3, 3), 0)
        
        return augmented
    
    def apply_pointcloud_weather_augmentation(self, points: np.ndarray, weather: str) -> np.ndarray:
        """åº”ç”¨å¤©æ°”å¢å¼ºæ•ˆæœåˆ°ç‚¹äº‘"""
        augmented = points.copy()
        
        if weather == 'rain':
            # é›¨å¤©ï¼šéšæœºç§»é™¤ä¸€äº›ç‚¹ï¼ˆæ¨¡æ‹Ÿé›¨æ»´é®æŒ¡ï¼‰
            keep_ratio = 0.9
            num_points = len(augmented)
            keep_indices = np.random.choice(num_points, int(num_points * keep_ratio), replace=False)
            augmented = augmented[keep_indices]
            
        elif weather == 'snow':
            # é›ªå¤©ï¼šæ·»åŠ éšæœºå™ªå£°åˆ°è·ç¦»
            noise = np.random.normal(0, 0.02, (len(augmented), 3))
            augmented[:, :3] += noise
            
        elif weather == 'fog':
            # é›¾å¤©ï¼šåŸºäºè·ç¦»éšæœºç§»é™¤è¿œè·ç¦»ç‚¹
            distances = np.sqrt(np.sum(augmented[:, :3]**2, axis=1))
            keep_mask = np.random.random(len(augmented)) > (distances / 100.0) * 0.3
            augmented = augmented[keep_mask]
        
        return augmented
    
    def after_train_epoch(self, runner) -> None:
        """è®­ç»ƒè½®æ¬¡ç»“æŸåçš„å¤„ç†"""
        current_epoch = runner.epoch
        
        print(f"\\nğŸ ç¬¬ {current_epoch + 1} è½®è®­ç»ƒå®Œæˆ")
        print(f"   ä¿å­˜çš„å¢å¼ºæ ·æœ¬æ•°: {self.saved_samples_count}")
        
        # ä¿å­˜å½“å‰è½®æ¬¡çš„ç­–ç•¥
        self.save_strategy(current_epoch + 1, self.current_strategy)
        
        # æ‰§è¡Œè‡ªåŠ¨éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.auto_validation and (current_epoch + 1) % 2 == 0:  # æ¯2è½®éªŒè¯ä¸€æ¬¡
            val_results = self.run_validation(runner, current_epoch + 1)
            
            # æ€§èƒ½åˆ†æ
            if self.performance_analysis and val_results:
                analysis = self.analyze_performance(val_results, current_epoch + 1)
                
                # ç­–ç•¥è‡ªé€‚åº”
                if self.strategy_adaptation:
                    self.adapt_strategy(analysis, current_epoch + 1)
        
        # æ›´æ–°è®­ç»ƒå†å²
        self.update_training_history(runner, current_epoch + 1)
    
    def save_strategy(self, epoch: int, strategy: Dict):
        """ä¿å­˜å¢å¼ºç­–ç•¥"""
        strategy_file = self.strategy_dir / f'strategy_epoch_{epoch}.yaml'
        
        strategy_with_timestamp = {
            'timestamp': datetime.now().isoformat(),
            'epoch': epoch,
            **strategy
        }
        
        with open(strategy_file, 'w') as f:
            yaml.dump(strategy_with_timestamp, f, default_flow_style=False)
        
        print(f"ğŸ“ ä¿å­˜å¢å¼ºç­–ç•¥: {strategy_file}")
    
    def run_validation(self, runner, epoch: int) -> Optional[Dict]:
        """è¿è¡ŒéªŒè¯è¯„ä¼°"""
        print(f"\\nğŸ” å¼€å§‹ç¬¬ {epoch} è½®éªŒè¯è¯„ä¼°...")
        
        try:
            # è¿è¡ŒéªŒè¯å¾ªç¯
            val_results = runner.val_loop.run()
            
            if val_results:
                # ä¿å­˜éªŒè¯ç»“æœ
                results_file = self.validation_dir / f'validation_epoch_{epoch}.json'
                with open(results_file, 'w') as f:
                    json.dump(val_results, f, indent=2)
                
                # æå–mAPå€¼
                mAP = self.extract_mAP(val_results)
                print(f"âœ… éªŒè¯å®Œæˆ - mAP: {mAP:.4f}")
                
                # ç”Ÿæˆå¯è§†åŒ–
                if self.visualization_enabled:
                    self.generate_validation_visualization(val_results, epoch)
                
                return val_results
            
        except Exception as e:
            print(f"âš ï¸ éªŒè¯è¯„ä¼°å¤±è´¥: {e}")
            return None
    
    def extract_mAP(self, val_results: Dict) -> float:
        """ä»éªŒè¯ç»“æœä¸­æå–mAPå€¼"""
        try:
            # æŸ¥æ‰¾mAPç›¸å…³çš„é”®
            map_keys = [k for k in val_results.keys() if 'mAP' in k or 'Overall' in k]
            if map_keys:
                return float(val_results[map_keys[0]])
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°mAPï¼Œå°è¯•å…¶ä»–æŒ‡æ ‡
            metric_keys = [k for k in val_results.keys() if isinstance(val_results[k], (int, float))]
            if metric_keys:
                return float(val_results[metric_keys[0]])
            
            return 0.0
            
        except:
            return 0.0
    
    def generate_validation_visualization(self, val_results: Dict, epoch: int):
        """ç”ŸæˆéªŒè¯ç»“æœå¯è§†åŒ–"""
        try:
            # åˆ›å»ºæ€§èƒ½å›¾è¡¨
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle(f'Validation Results - Epoch {epoch}', fontsize=16)
            
            # æå–å„ç±»åˆ«æ€§èƒ½
            classes = ['Pedestrian', 'Cyclist', 'Car']
            metrics = ['Easy', 'Moderate', 'Hard']
            
            # ç»˜åˆ¶å„ç±»åˆ«mAP
            for i, cls in enumerate(classes):
                ax = axes[i // 2, i % 2] if i < 3 else axes[1, 1]
                
                easy_key = f'KITTI/{cls}_3D_easy'
                moderate_key = f'KITTI/{cls}_3D_moderate' 
                hard_key = f'KITTI/{cls}_3D_hard'
                
                values = []
                for key in [easy_key, moderate_key, hard_key]:
                    values.append(val_results.get(key, 0))
                
                ax.bar(metrics, values, alpha=0.7)
                ax.set_title(f'{cls} Detection Performance')
                ax.set_ylabel('mAP')
                ax.set_ylim(0, 1.0)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for j, v in enumerate(values):
                    ax.text(j, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
            
            # ç»˜åˆ¶æ•´ä½“æ€§èƒ½è¶‹åŠ¿
            if len(self.training_history['val_maps']) > 0:
                ax = axes[1, 1]
                epochs = self.training_history['epochs']
                maps = self.training_history['val_maps'] 
                
                ax.plot(epochs, maps, 'b-o', linewidth=2, markersize=6)
                ax.set_title('Overall mAP Trend')
                ax.set_xlabel('Epoch')
                ax.set_ylabel('mAP')
                ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            viz_file = self.visualization_dir / f'validation_epoch_{epoch}.png'
            plt.savefig(str(viz_file), dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“Š ç”ŸæˆéªŒè¯å¯è§†åŒ–: {viz_file}")
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
    
    def analyze_performance(self, val_results: Dict, epoch: int) -> Dict:
        """åˆ†ææ€§èƒ½ç»“æœ"""
        print(f"\\nğŸ“ˆ å¼€å§‹æ€§èƒ½åˆ†æ...")
        
        analysis = {
            'epoch': epoch,
            'timestamp': datetime.now().isoformat(),
            'overall_mAP': self.extract_mAP(val_results),
            'class_performance': {},
            'improvement_analysis': {},
            'recommendations': []
        }
        
        # åˆ†æå„ç±»åˆ«æ€§èƒ½
        classes = ['Pedestrian', 'Cyclist', 'Car']
        for cls in classes:
            easy_key = f'KITTI/{cls}_3D_easy'
            moderate_key = f'KITTI/{cls}_3D_moderate'
            hard_key = f'KITTI/{cls}_3D_hard'
            
            class_perf = {
                'easy': val_results.get(easy_key, 0),
                'moderate': val_results.get(moderate_key, 0),
                'hard': val_results.get(hard_key, 0),
                'average': np.mean([val_results.get(k, 0) for k in [easy_key, moderate_key, hard_key]])
            }
            
            analysis['class_performance'][cls] = class_perf
        
        # æ”¹è¿›åˆ†æ
        if len(self.training_history['val_maps']) > 0:
            prev_mAP = self.training_history['val_maps'][-1]
            current_mAP = analysis['overall_mAP']
            improvement = current_mAP - prev_mAP
            
            analysis['improvement_analysis'] = {
                'previous_mAP': prev_mAP,
                'current_mAP': current_mAP,
                'improvement': improvement,
                'improvement_rate': improvement / max(prev_mAP, 0.001)
            }
        
        # ç”Ÿæˆå»ºè®®
        analysis['recommendations'] = self.generate_recommendations(analysis)
        
        # ä¿å­˜åˆ†æç»“æœ
        analysis_file = self.analysis_dir / f'analysis_epoch_{epoch}.json'
        with open(analysis_file, 'w') as f:
            json.dump(analysis, f, indent=2)
        
        print(f"ğŸ“‹ æ€§èƒ½åˆ†æå®Œæˆ - æ•´ä½“mAP: {analysis['overall_mAP']:.4f}")
        
        return analysis
    
    def generate_recommendations(self, analysis: Dict) -> List[str]:
        """åŸºäºæ€§èƒ½åˆ†æç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºæ•´ä½“mAPç»™å‡ºå»ºè®®
        overall_mAP = analysis['overall_mAP']
        if overall_mAP < 0.3:
            recommendations.append("æ•´ä½“æ€§èƒ½è¾ƒä½ï¼Œå»ºè®®å¢åŠ åŸºç¡€æ•°æ®å¢å¼ºå¼ºåº¦")
        elif overall_mAP < 0.5:
            recommendations.append("æ€§èƒ½ä¸­ç­‰ï¼Œå»ºè®®ä¼˜åŒ–å›°éš¾æ ·æœ¬çš„å¢å¼ºç­–ç•¥")
        else:
            recommendations.append("æ€§èƒ½è‰¯å¥½ï¼Œå»ºè®®ç»´æŒå½“å‰ç­–ç•¥å¹¶è¿›è¡Œå¾®è°ƒ")
        
        # åŸºäºç±»åˆ«æ€§èƒ½ç»™å‡ºå»ºè®®
        for cls, perf in analysis['class_performance'].items():
            avg_perf = perf['average']
            if avg_perf < 0.2:
                recommendations.append(f"{cls}ç±»åˆ«æ€§èƒ½å¾ˆä½ï¼Œéœ€è¦å¢åŠ é’ˆå¯¹æ€§å¢å¼º")
            elif avg_perf < 0.4:
                recommendations.append(f"{cls}ç±»åˆ«æ€§èƒ½åä½ï¼Œå»ºè®®è°ƒæ•´å¢å¼ºå‚æ•°")
        
        # åŸºäºæ”¹è¿›è¶‹åŠ¿ç»™å‡ºå»ºè®®
        if 'improvement_analysis' in analysis:
            improvement = analysis['improvement_analysis']['improvement']
            if improvement < -0.05:
                recommendations.append("æ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼Œå»ºè®®é™ä½å¢å¼ºå¼ºåº¦")
            elif improvement > 0.05:
                recommendations.append("æ€§èƒ½æå‡æ˜¾è‘—ï¼Œå¯ä»¥é€‚å½“å¢åŠ å¢å¼ºéš¾åº¦")
        
        return recommendations
    
    def adapt_strategy(self, analysis: Dict, epoch: int):
        """åŸºäºæ€§èƒ½åˆ†æè‡ªé€‚åº”è°ƒæ•´å¢å¼ºç­–ç•¥"""
        print(f"\\nğŸ”„ å¼€å§‹ç­–ç•¥è‡ªé€‚åº”è°ƒæ•´...")
        
        old_strategy = self.current_strategy.copy()
        
        # åŸºäºæ•´ä½“æ€§èƒ½è°ƒæ•´
        overall_mAP = analysis['overall_mAP']
        threshold = self.current_strategy['adaptation_params']['performance_threshold']
        
        if overall_mAP < threshold * 0.7:  # æ€§èƒ½å¾ˆå·®
            # é™ä½å¢å¼ºå¼ºåº¦
            for weather in ['rain', 'snow', 'fog']:
                if weather in self.current_strategy['intensity_levels']:
                    self.current_strategy['intensity_levels'][weather] *= 0.9
                    
        elif overall_mAP > threshold * 1.2:  # æ€§èƒ½å¾ˆå¥½
            # å¢åŠ å¢å¼ºå¼ºåº¦
            for weather in ['rain', 'snow', 'fog']:
                if weather in self.current_strategy['intensity_levels']:
                    self.current_strategy['intensity_levels'][weather] *= 1.1
        
        # åŸºäºç±»åˆ«æ€§èƒ½è°ƒæ•´å¤©æ°”æ¦‚ç‡
        class_performances = analysis['class_performance']
        
        # å¦‚æœPedestrianå’ŒCyclistæ€§èƒ½è¾ƒå·®ï¼Œå¢åŠ é›¨é›¾å¤©æ°”æ¦‚ç‡ï¼ˆè¿™äº›å¤©æ°”å¯¹å°ç›®æ ‡æ£€æµ‹æ›´æœ‰æŒ‘æˆ˜ï¼‰
        small_object_perf = (class_performances['Pedestrian']['average'] + 
                            class_performances['Cyclist']['average']) / 2
        
        if small_object_perf < 0.3:
            self.current_strategy['weather_probabilities']['rain'] *= 1.2
            self.current_strategy['weather_probabilities']['fog'] *= 1.2
            self.current_strategy['weather_probabilities']['clear'] *= 0.8
        
        # è§„èŒƒåŒ–æ¦‚ç‡
        total_prob = sum(self.current_strategy['weather_probabilities'].values())
        for weather in self.current_strategy['weather_probabilities']:
            self.current_strategy['weather_probabilities'][weather] /= total_prob
        
        # é™åˆ¶å¼ºåº¦èŒƒå›´
        min_intensity = self.current_strategy['adaptation_params']['min_intensity']
        max_intensity = self.current_strategy['adaptation_params']['max_intensity']
        
        for weather in self.current_strategy['intensity_levels']:
            intensity = self.current_strategy['intensity_levels'][weather]
            self.current_strategy['intensity_levels'][weather] = np.clip(intensity, min_intensity, max_intensity)
        
        print(f"ğŸ¯ ç­–ç•¥è°ƒæ•´å®Œæˆ:")
        print(f"   æ—§ç­–ç•¥å¤©æ°”æ¦‚ç‡: {old_strategy['weather_probabilities']}")
        print(f"   æ–°ç­–ç•¥å¤©æ°”æ¦‚ç‡: {self.current_strategy['weather_probabilities']}")
        print(f"   å¼ºåº¦è°ƒæ•´: {self.current_strategy['intensity_levels']}")
    
    def update_training_history(self, runner, epoch: int):
        """æ›´æ–°è®­ç»ƒå†å²è®°å½•"""
        # è·å–å½“å‰è®­ç»ƒæŸå¤±
        current_loss = getattr(runner.message_hub, 'train_loss', 0)
        
        self.training_history['epochs'].append(epoch)
        self.training_history['losses'].append(current_loss)
        self.training_history['strategies'].append(self.current_strategy.copy())
        
        # å¦‚æœæœ‰éªŒè¯ç»“æœï¼Œæ·»åŠ åˆ°å†å²ä¸­
        if hasattr(self, '_last_val_mAP'):
            self.training_history['val_maps'].append(self._last_val_mAP)
        
        # ä¿å­˜å†å²è®°å½•
        history_file = self.work_dir / 'training_history.json'
        with open(history_file, 'w') as f:
            json.dump(self.training_history, f, indent=2, default=str)
    
    def after_run(self, runner) -> None:
        """è®­ç»ƒå®Œæˆåçš„æœ€ç»ˆå¤„ç†"""
        print(f"\\nğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼")
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.generate_final_report()
        
        print(f"ğŸ“Š å®Œæ•´è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜åˆ°: {self.work_dir}")
        print(f"   - å¢å¼ºæ ·æœ¬è¾“å‡º: {self.aug_output_dir}")
        print(f"   - å¢å¼ºç­–ç•¥å†å²: {self.strategy_dir}")
        print(f"   - éªŒè¯ç»“æœ: {self.validation_dir}")
        print(f"   - å¯è§†åŒ–ç»“æœ: {self.visualization_dir}")
        print(f"   - æ€§èƒ½åˆ†æ: {self.analysis_dir}")
    
    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆè®­ç»ƒæŠ¥å‘Š"""
        try:
            report = {
                'training_summary': {
                    'total_epochs': len(self.training_history['epochs']),
                    'final_loss': self.training_history['losses'][-1] if self.training_history['losses'] else None,
                    'final_mAP': self.training_history['val_maps'][-1] if self.training_history['val_maps'] else None,
                    'best_mAP': max(self.training_history['val_maps']) if self.training_history['val_maps'] else None
                },
                'strategy_evolution': self.training_history['strategies'],
                'performance_trend': {
                    'epochs': self.training_history['epochs'],
                    'losses': self.training_history['losses'],
                    'val_maps': self.training_history['val_maps']
                },
                'final_recommendations': self.generate_final_recommendations()
            }
            
            # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
            report_file = self.work_dir / 'final_training_report.json'
            with open(report_file, 'w') as f:
                json.dump(report, f, indent=2, default=str)
            
            # ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–
            self.generate_final_visualization()
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def generate_final_recommendations(self) -> List[str]:
        """ç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        recommendations = [
            "åŸºäºå®Œæ•´è®­ç»ƒè¿‡ç¨‹çš„å»ºè®®:",
            "1. æ ¹æ®ä¿å­˜çš„å¢å¼ºç­–ç•¥å†å²ï¼Œé€‰æ‹©æ€§èƒ½æœ€å¥½çš„ç­–ç•¥ç”¨äºåç»­è®­ç»ƒ",
            "2. åˆ†æå„ç±»åˆ«æ£€æµ‹æ€§èƒ½ï¼Œé’ˆå¯¹æ€§ä¼˜åŒ–æ•°æ®å¢å¼ºå‚æ•°",
            "3. è€ƒè™‘ç»“åˆå¤šç§å¤©æ°”æ¡ä»¶è¿›è¡Œæ··åˆå¢å¼º",
            "4. æ ¹æ®å¯è§†åŒ–ç»“æœè°ƒæ•´éªŒè¯é¢‘ç‡å’Œå¢å¼ºå¼ºåº¦"
        ]
        
        if self.training_history['val_maps']:
            best_epoch = self.training_history['epochs'][np.argmax(self.training_history['val_maps'])]
            recommendations.append(f"5. æœ€ä½³æ€§èƒ½å‡ºç°åœ¨ç¬¬{best_epoch}è½®ï¼Œå»ºè®®å‚è€ƒè¯¥è½®çš„å¢å¼ºç­–ç•¥")
        
        return recommendations
    
    def generate_final_visualization(self):
        """ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–å›¾è¡¨"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('Complete Training Analysis', fontsize=16)
            
            # è®­ç»ƒæŸå¤±è¶‹åŠ¿
            if self.training_history['losses']:
                axes[0, 0].plot(self.training_history['epochs'], self.training_history['losses'], 'b-o')
                axes[0, 0].set_title('Training Loss Trend')
                axes[0, 0].set_xlabel('Epoch')
                axes[0, 0].set_ylabel('Loss')
                axes[0, 0].grid(True, alpha=0.3)
            
            # éªŒè¯mAPè¶‹åŠ¿
            if self.training_history['val_maps']:
                axes[0, 1].plot(self.training_history['epochs'][:len(self.training_history['val_maps'])], 
                               self.training_history['val_maps'], 'g-o')
                axes[0, 1].set_title('Validation mAP Trend')
                axes[0, 1].set_xlabel('Epoch')
                axes[0, 1].set_ylabel('mAP')
                axes[0, 1].grid(True, alpha=0.3)
            
            # å¢å¼ºç­–ç•¥æ¼”åŒ– - å¤©æ°”æ¦‚ç‡
            if self.training_history['strategies']:
                weather_types = ['rain', 'snow', 'fog']
                for weather in weather_types:
                    probs = [s['weather_probabilities'][weather] for s in self.training_history['strategies']]
                    axes[1, 0].plot(self.training_history['epochs'], probs, label=weather, marker='o')
                
                axes[1, 0].set_title('Weather Probability Evolution')
                axes[1, 0].set_xlabel('Epoch')
                axes[1, 0].set_ylabel('Probability')
                axes[1, 0].legend()
                axes[1, 0].grid(True, alpha=0.3)
            
            # å¢å¼ºå¼ºåº¦æ¼”åŒ–
            if self.training_history['strategies']:
                weather_types = ['rain', 'snow', 'fog']
                for weather in weather_types:
                    intensities = [s.get('intensity_levels', {}).get(weather, 0) for s in self.training_history['strategies']]
                    axes[1, 1].plot(self.training_history['epochs'], intensities, label=weather, marker='s')
                
                axes[1, 1].set_title('Intensity Level Evolution')
                axes[1, 1].set_xlabel('Epoch')
                axes[1, 1].set_ylabel('Intensity')
                axes[1, 1].legend()
                axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜æœ€ç»ˆå¯è§†åŒ–
            final_viz_file = self.visualization_dir / 'final_training_analysis.png'
            plt.savefig(str(final_viz_file), dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“Š ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–: {final_viz_file}")
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–å¤±è´¥: {e}")


class ROSEEnhancedTrainer:
    """ROSEå¢å¼ºè®­ç»ƒå™¨ä¸»ç±»"""
    
    def __init__(self, config_path: str, work_dir: str):
        self.config_path = config_path
        self.work_dir = Path(work_dir)
        self.work_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½é…ç½®
        self.cfg = Config.fromfile(config_path)
        
        # æ·»åŠ å¢å¼ºè®­ç»ƒé’©å­
        self.add_enhanced_hook()
    
    def add_enhanced_hook(self):
        """æ·»åŠ å¢å¼ºè®­ç»ƒé’©å­åˆ°é…ç½®"""
        enhanced_hook = {
            'type': 'EnhancedROSETrainingHook',
            'work_dir': str(self.work_dir),
            'save_augmented_samples': True,
            'samples_per_epoch': 50,
            'visualization_enabled': True,
            'auto_validation': True,
            'strategy_adaptation': True,
            'performance_analysis': True,
            'priority': 'NORMAL'
        }
        
        if not hasattr(self.cfg, 'custom_hooks'):
            self.cfg.custom_hooks = []
        
        self.cfg.custom_hooks.append(enhanced_hook)
        
        # æ›´æ–°å·¥ä½œç›®å½•
        self.cfg.work_dir = str(self.work_dir)
    
    def train(self):
        """å¼€å§‹å¢å¼ºè®­ç»ƒæµç¨‹"""
        print("ğŸš€ å¯åŠ¨ROSEå¢å¼ºè®­ç»ƒç³»ç»Ÿ...")
        
        # åˆ›å»ºå¹¶å¯åŠ¨è®­ç»ƒå™¨
        runner = Runner.from_cfg(self.cfg)
        runner.train()
        
        print("âœ… ROSEå¢å¼ºè®­ç»ƒå®Œæˆï¼")
        
        return runner


if __name__ == '__main__':
    # ä½¿ç”¨ç¤ºä¾‹
    trainer = ROSEEnhancedTrainer(
        config_path='configs/rose_simple_no_ssl.py',
        work_dir='work_dirs/enhanced_rose_training'
    )
    
    trainer.train()